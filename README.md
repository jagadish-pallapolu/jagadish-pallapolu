## Hi there ðŸ‘‹

# I am Jagadish Pallapolu

### Data Engineer | Generative AI Enthusiast

---

## About Me

An experienced Data Engineer with over six years in the field, specializing in building robust ETL pipelines, managing data warehouses, and integrating advanced Generative AI technologies. Adept at utilizing Google Cloud Platform (GCP) tools, containerization technologies, and orchestration frameworks to deliver scalable and efficient solutions. Passionate about solving complex data challenges and exploring AI-driven innovations.

---

## Skills

- **Data Engineering**: BigQuery, Apache Airflow, Apache PySpark, ETL pipelines
- **Google Cloud Expertise**: Cloud Run, Vertex AI, Data Fusion, Cloud Storage, Pub/Sub
- **Programming**: Python (Flask, Pandas, Streamlit), SQL
- **DevOps & Automation**: Docker, Google Cloud Build, GitLab, CI/CD
- **Web Scraping**: BeautifulSoup, Scrapy
- **Reporting and Visualization**: Google Data Studio, Google Sheets

---

## Projects

### Generative AI Chatbot

- **Objective**: Developed a Proof of Concept (POC) chatbot to efficiently address user queries by leveraging the content of PDF documents, including company policies and guidelines.
- **Technologies**:
  - Google Vertex AI for generative AI modeling
  - LangChain Framework for application logic
  - Streamlit for building the user interface
  - Google Cloud Run for hosting the containerized application
- **Outcomes**: Delivered an efficient, user-friendly chatbot prototype deployed on GCP, showcasing advanced AI integration for enterprise applications.

### ETL Pipelines with Google Cloud Data Fusion

- **Objective**: Built ETL pipelines to process and transform raw data for loading into BigQuery.
- **Technologies**:
  - Google Cloud Data Fusion for ETL orchestration
  - Wrangler directives for data cleaning
  - CSV and Parquet file handling for data lake integration
- **Outcomes**: Streamlined the data loading process into BigQuery, enhancing the efficiency of downstream analytics.

### Web Scraping Automation

- **Objective**: Automated data extraction from websites to gather market intelligence.
- **Technologies**:
  - Python with BeautifulSoup and Scrapy
  - Data formats: JSON, CSV, and Excel
- **Outcomes**: Enabled real-time data collection, saving time and effort for data analysis tasks.

### Reporting Automation

- **Objective**: Designed macros and scripts to automate data reporting workflows.
- **Technologies**:
  - Microsoft Excel macros
  - Google Data Studio for visualization
- **Outcomes**: Reduced manual reporting time, improved data accuracy, and facilitated actionable insights.

---

## Contact

- **Email**: [jagadish.pallapolu@gmail.com](mailto:jagadish.pallapolu@gmail.com)
- **Location**: Bengaluru, India
- **[LinkedIn](https://www.linkedin.com/in/jagadish-n-56b708129/)**


<!--
**jagadish-pallapolu/jagadish-pallapolu** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
